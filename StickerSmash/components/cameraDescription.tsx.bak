import React, { useState, useEffect, useRef } from 'react';
import { StyleSheet, Text, View, TouchableOpacity, Dimensions, ActivityIndicator, Platform, useWindowDimensions, Linking } from 'react-native';
// import { CameraView, useCameraPermissions } from 'expo-camera';
import { Camera, useCameraDevice, useCameraPermission } from 'react-native-vision-camera';
import * as ImageManipulator from 'expo-image-manipulator';
import Svg, { Rect, Text as SvgText } from 'react-native-svg';
import {fetchPrediction} from '../api/fetchPrediction';

interface Detection {
  x: number;
  y: number;
  width: number;
  height: number;
  label: string;
}

export default function CameraDescription() {
  const {width: SCREEN_WIDTH, height: SCREEN_HEIGHT } = useWindowDimensions();
  
  // react-native-vision-camera
  const { hasPermission, requestPermission } = useCameraPermission();
  // expo-camera
  // const [permission, requestPermission] = useCameraPermissions();
  const [facing, setFacing] = useState<'front' | 'back'>('back');
  
  const device = useCameraDevice(facing);

  const [detections, setDetections] = useState<Detection[]>([]);// 検出結果格納用(座標・ラベル)
  const [isDetectingFrag, setIsDetectingFrag] = useState(false);// 絵画の要素探す通信状態管理
  const [isDetectingCamvas, setIsDetectingCamvas] = useState(false);// 絵画フレーム探す通信状態管理

  // react-native-vision-camera
  const cameraRef = useRef<Camera>(null);
  // expo-camera
  // const cameraRef = useRef<CameraView>(null);

  useEffect(() => {
    if(!hasPermission){
      requestPermission();
    }
  }, [hasPermission]);

  const photoData = async () => {
    if(!cameraRef.current || !device) return null;

    try {
      // react-native-vision-camera
      // カメラ画像を取得する
      const photoFile = await cameraRef.current.takePhoto({
        flash: 'off',
        enableShutterSound: false,
      });
      
      const manipulated = await ImageManipulator.manipulateAsync(
        photoFile.path,
        [{ resize: { width: 640 } }],
        { compress: 0.5, format: ImageManipulator.SaveFormat.JPEG, base64: true }
      );

      return {
        width: manipulated.width,
        height: manipulated.height,
        base64: manipulated.base64,
      }

      // expo-camera
      // const options = {
      //   base64: true,
      //   quality: 0.5,
      //   skipProcessing: true,
      // };

      // const photo = await cameraRef.current.takePictureAsync(options);

      // return photo;
    }catch (error) {
      console.warn("Capture Error:", error);
      return null;
    }
  };

  // 物体検出用外部API
  const detectObjects = async () => {
    // 通信状態になっているかcameraRefに状態が保存されている場合はapiはたたかない
    if(isDetectingFrag) return;

    try {
      // 通信状態に更新
      setIsDetectingFrag(true);

      // オプションを引数にするとその設定に応じた画像を取得するtakePictureAsync()を使用
      const photo = await photoData();

      if(!photo || !photo.base64) return;

      
      // 外部APIに取得した画像をPOSTメソッドで送信
      const result = await fetchPrediction(photo.base64);
      
      let imgW = photo.width;
      let imgH = photo.height;
      // let isRotated = false;

      // if (Platform.OS !== 'web') {
      //   imgW = Math.min(photo.width, photo.height);
      //   imgH = Math.max(photo.width, photo.height);
      //   isRotated = true;
      // }

      const scale = Math.max(SCREEN_WIDTH / imgW, SCREEN_HEIGHT / imgH);

      const dx = (SCREEN_WIDTH - imgW * scale) / 2;
      const dy = (SCREEN_HEIGHT - imgH * scale) / 2;
      
      if (result.predictions && result.predictions.length > 0) {
        // 座標変換処理
        const adaptedDetections = result.predictions.map((p: any) => {
          
          let finalX, finalY, finalWidth, finalHeight;
          const roboX = p.x;
          const roboY = p.y;
          const roboW = p.width;
          const roboH = p.height;

          // if (isRotated) {
             // 【モバイル（縦画面）用】: 90度回転しているのでXとYを入れ替える
             // Roboflow X -> 画面 Y
             // Roboflow Y -> 画面 X
            //  finalY = (roboX - roboW / 2) * scale + dy;
            //  finalX = (roboY - roboH / 2) * scale + dx;
            //  finalHeight = roboW * scale;
            //  finalWidth = roboH * scale;
          // } else {
          //    // 【Web / PCブラウザ用】: 回転なし。そのままマッピング
             finalX = (roboX - roboW / 2) * scale + dx;
             finalY = (roboY - roboH / 2) * scale + dy;
             finalWidth = roboW * scale;
             finalHeight = roboH * scale;
          // }

          if(facing === 'front') {
            finalX = SCREEN_WIDTH -finalX -finalWidth;
          }

          return {
            ...p,
            x: finalX,
            y: finalY,
            width: finalWidth,
            height: finalHeight,
            label: p.class, // APIによっては p.class または p.label
          };
        });
        
        // 確認用
        console.log("Predictions:", adaptedDetections[0]);
        console.log("WinW:", SCREEN_WIDTH);
        console.log("WinHeight:", SCREEN_HEIGHT);
        // APIが検出した物体の座標とラベルを格納
        setDetections(adaptedDetections);
      } else {
        setDetections([]);
      }

    } catch (error) {
      console.log("Detection Error:", (error as Error).message);
    } finally {
      // 通信状態更新
      setIsDetectingFrag(false);
    }
  };

  const talkWithAI = async () => {
    if(isDetectingCamvas) return;
    try{
      setIsDetectingCamvas(true);
    }finally{
      setIsDetectingCamvas(false);
    }
  };

  useEffect(() => {
    let isMounted = true; // コンポーネントがマウントされているか追跡

    const loop = async () => {
      // 権限があり、かつマウント中なら実行
      if (hasPermission && isMounted && device) {
        await detectObjects();
        // 処理が終わってから次の実行まで少し待機（例: 100ms）
        if (isMounted) setTimeout(loop, 100); 
      }
    };

    if (hasPermission) {
      loop(); // ループ開始
    }

    return () => {
      isMounted = false; // クリーンアップ
    };
  }, [hasPermission, device]);

  // 権限の確認中
  if (hasPermission) {
    return (
      <View style={styles.centered}>
        <Text style={styles.message}>カメラの使用許可が必要です</Text>
        <TouchableOpacity style={styles.button} onPress={() => Linking.openSettings()}>
          <Text style={styles.buttonText}>設定を開く</Text>
        </TouchableOpacity>
      </View>
    );
  }

  if (device == null) {
    return <ActivityIndicator size="large" color="#2196F3" style={{flex: 1}} />;
  }

  function toggleCamera() {
    setFacing(current => (current === 'front' ? 'back' : 'front'));
  }

  return (
    <View style={styles.container}>
      {/* react-native-vision-camera */}
      <Camera
        ref={cameraRef}
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        photo={true}
      />
      {/* expo-camera */}
      {/* <CameraView 
        ref={cameraRef} 
        style={StyleSheet.absoluteFillObject} 
        facing={facing}
      > */}
        <View style={StyleSheet.absoluteFillObject} pointerEvents="box-none">
          <Svg style={styles.rect} pointerEvents="none">
            {/* svgレイヤーのテスト用 */}
            {/* <Rect x="50" y="50" width="100" height="100" stroke="red" strokeWidth="5" fill="transparent" /> */}
            {detections.map((item, index) => (
              <React.Fragment key={`box-${index}`}>
                <Rect
                  x={item.x}
                  y={item.y}
                  width={item.width}
                  height={item.height}
                  stroke="#00FF00"
                  strokeWidth="3"
                  fill="transparent"
                  />
                <SvgText
                  x={item.x}
                  y={item.y > 25 ? item.y - 10 : item.y + 25}
                  fill="#00FF00"
                  fontSize="18"
                  fontWeight="bold"
                  >
                  {item.label}
                </SvgText>
              </React.Fragment>
            ))}
          </Svg>
        </View>

        {/* カメラ映像の上にボタンなどを重ねたい場合はここに記述 */}
        <View style={styles.overlay} pointerEvents="box-none">
          <View>
            <View style={[
              styles.indicator,
              { backgroundColor: isDetectingFrag ? '#FFA500' : '#00FF00' }
            ]} />
            <Text style={{color: 'white', fontWeight: 'bold'}}>
              {isDetectingFrag ? "推論中..." : "ライブビュー"}
            </Text>
          </View>
          
          <View style={styles.controls}>
            <TouchableOpacity style={styles.flipButton} onPress={toggleCamera}>
              <Text style={styles.flipText}>カメラ切替</Text>
            </TouchableOpacity>
          </View>
        </View>
      {/* </CameraView> */}
    </View>
  );
}

const styles = StyleSheet.create({
  centered: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#121212',
    padding: 20,
  },
  container: {
    flex: 1, // 親要素を画面全体に
    backgroundColor: '#000',
  },
  rect: {
    flex: 1,
    backgroundColor: '#00000000',
  },
  message: {
    textAlign: 'center',
    color: '#fff',
    marginBottom: 24,
    fontSize: 18,
  },
  button: {
    backgroundColor: '#2196F3',
    paddingHorizontal: 40,
    paddingVertical: 14,
    borderRadius: 30,
    elevation: 3,
  },
  buttonText: {
    color: '#fff',
    fontWeight: 'bold',
    fontSize: 16,
    letterSpacing: 1,
  },
  overlay: {
    flex: 1,
    padding: 30,
    justifyContent: 'space-between',
  },
  indicator: {
    width: 10,
    height: 10,
    borderRadius: 5,
    marginRight: 10,
  },
  controls: {
    alignItems: 'center',
  },
  flipButton: {
    backgroundColor: 'rgba(255,255,255,0.15)',
    paddingHorizontal: 25,
    paddingVertical: 15,
    borderRadius: 30,
    borderWidth: 1.5,
    borderColor: 'rgba(255,255,255,0.4)',
  },
  flipText: {
    color: '#fff',
    fontSize: 14,
    fontWeight: 'bold',
  },
});